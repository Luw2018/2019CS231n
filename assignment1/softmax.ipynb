{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "    try:\n",
    "       del X_train, y_train\n",
    "       del X_test, y_test\n",
    "       print('Clear previously loaded data.')\n",
    "    except:\n",
    "       pass\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.332465\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 1**\n",
    "\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$ \n",
    "Since the weight matrix W is uniformly and randomly selected, the prediction probability of each category is uniformly distributed, and the number of categories in the program is 10, so the probability of each category is equal to 1/10. Therefore, the cross entropy for each example is -log(0.1), which should equal the loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 3.750485 analytic: 3.750485, relative error: 2.101198e-09\n",
      "numerical: -2.511664 analytic: -2.511664, relative error: 3.661209e-08\n",
      "numerical: -0.846448 analytic: -0.846448, relative error: 1.305037e-09\n",
      "numerical: 0.902847 analytic: 0.902847, relative error: 4.094399e-08\n",
      "numerical: -0.250860 analytic: -0.250860, relative error: 1.540374e-07\n",
      "numerical: 1.827793 analytic: 1.827793, relative error: 2.274405e-08\n",
      "numerical: 0.077805 analytic: 0.077805, relative error: 7.518700e-07\n",
      "numerical: -1.309413 analytic: -1.309413, relative error: 6.437518e-09\n",
      "numerical: -2.372522 analytic: -2.372522, relative error: 1.266315e-08\n",
      "numerical: -0.416075 analytic: -0.416075, relative error: 9.701463e-09\n",
      "numerical: 0.020243 analytic: 0.020866, relative error: 1.516608e-02\n",
      "numerical: 1.789242 analytic: 1.788248, relative error: 2.779729e-04\n",
      "numerical: 0.196946 analytic: 0.198500, relative error: 3.931063e-03\n",
      "numerical: -2.004325 analytic: -2.007384, relative error: 7.624890e-04\n",
      "numerical: 1.160916 analytic: 1.155657, relative error: 2.270310e-03\n",
      "numerical: 2.151839 analytic: 2.146633, relative error: 1.211141e-03\n",
      "numerical: -0.570187 analytic: -0.568884, relative error: 1.144094e-03\n",
      "numerical: -2.387465 analytic: -2.393670, relative error: 1.297688e-03\n",
      "numerical: -0.331225 analytic: -0.324481, relative error: 1.028561e-02\n",
      "numerical: 1.518482 analytic: 1.526058, relative error: 2.488653e-03\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.332465e+00 computed in 0.294764s\n",
      "vectorized loss: 2.332465e+00 computed in 0.040481s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 2000: loss 224.758567\n",
      "iteration 100 / 2000: loss 193.543809\n",
      "iteration 200 / 2000: loss 168.116221\n",
      "iteration 300 / 2000: loss 145.844825\n",
      "iteration 400 / 2000: loss 126.691457\n",
      "iteration 500 / 2000: loss 110.388079\n",
      "iteration 600 / 2000: loss 95.892160\n",
      "iteration 700 / 2000: loss 83.364218\n",
      "iteration 800 / 2000: loss 72.698930\n",
      "iteration 900 / 2000: loss 63.369099\n",
      "iteration 1000 / 2000: loss 55.314957\n",
      "iteration 1100 / 2000: loss 48.272414\n",
      "iteration 1200 / 2000: loss 42.056545\n",
      "iteration 1300 / 2000: loss 36.834915\n",
      "iteration 1400 / 2000: loss 32.172189\n",
      "iteration 1500 / 2000: loss 28.223498\n",
      "iteration 1600 / 2000: loss 24.871112\n",
      "iteration 1700 / 2000: loss 21.662703\n",
      "iteration 1800 / 2000: loss 19.119709\n",
      "iteration 1900 / 2000: loss 16.856831\n",
      "iteration 0 / 2000: loss 252.871652\n",
      "iteration 100 / 2000: loss 213.587048\n",
      "iteration 200 / 2000: loss 181.589354\n",
      "iteration 300 / 2000: loss 154.643175\n",
      "iteration 400 / 2000: loss 132.097728\n",
      "iteration 500 / 2000: loss 112.461593\n",
      "iteration 600 / 2000: loss 95.871863\n",
      "iteration 700 / 2000: loss 81.908307\n",
      "iteration 800 / 2000: loss 69.895304\n",
      "iteration 900 / 2000: loss 59.901285\n",
      "iteration 1000 / 2000: loss 51.254457\n",
      "iteration 1100 / 2000: loss 43.763979\n",
      "iteration 1200 / 2000: loss 37.629730\n",
      "iteration 1300 / 2000: loss 32.310402\n",
      "iteration 1400 / 2000: loss 27.651329\n",
      "iteration 1500 / 2000: loss 23.969658\n",
      "iteration 1600 / 2000: loss 20.738115\n",
      "iteration 1700 / 2000: loss 17.891638\n",
      "iteration 1800 / 2000: loss 15.492731\n",
      "iteration 1900 / 2000: loss 13.475757\n",
      "iteration 0 / 2000: loss 281.935218\n",
      "iteration 100 / 2000: loss 234.098444\n",
      "iteration 200 / 2000: loss 195.547306\n",
      "iteration 300 / 2000: loss 163.121340\n",
      "iteration 400 / 2000: loss 136.253936\n",
      "iteration 500 / 2000: loss 113.837181\n",
      "iteration 600 / 2000: loss 95.110764\n",
      "iteration 700 / 2000: loss 79.898528\n",
      "iteration 800 / 2000: loss 66.803107\n",
      "iteration 900 / 2000: loss 56.063761\n",
      "iteration 1000 / 2000: loss 47.128189\n",
      "iteration 1100 / 2000: loss 39.556299\n",
      "iteration 1200 / 2000: loss 33.403117\n",
      "iteration 1300 / 2000: loss 28.167427\n",
      "iteration 1400 / 2000: loss 23.748360\n",
      "iteration 1500 / 2000: loss 20.267070\n",
      "iteration 1600 / 2000: loss 17.187484\n",
      "iteration 1700 / 2000: loss 14.665158\n",
      "iteration 1800 / 2000: loss 12.463416\n",
      "iteration 1900 / 2000: loss 10.761892\n",
      "iteration 0 / 2000: loss 312.997458\n",
      "iteration 100 / 2000: loss 254.967853\n",
      "iteration 200 / 2000: loss 208.276948\n",
      "iteration 300 / 2000: loss 170.541750\n",
      "iteration 400 / 2000: loss 139.709355\n",
      "iteration 500 / 2000: loss 114.449443\n",
      "iteration 600 / 2000: loss 93.716666\n",
      "iteration 700 / 2000: loss 77.023633\n",
      "iteration 800 / 2000: loss 63.472247\n",
      "iteration 900 / 2000: loss 52.223759\n",
      "iteration 1000 / 2000: loss 42.991510\n",
      "iteration 1100 / 2000: loss 35.587836\n",
      "iteration 1200 / 2000: loss 29.383793\n",
      "iteration 1300 / 2000: loss 24.386906\n",
      "iteration 1400 / 2000: loss 20.269595\n",
      "iteration 1500 / 2000: loss 16.975308\n",
      "iteration 1600 / 2000: loss 14.246615\n",
      "iteration 1700 / 2000: loss 12.020205\n",
      "iteration 1800 / 2000: loss 10.200627\n",
      "iteration 1900 / 2000: loss 8.750114\n",
      "iteration 0 / 2000: loss 346.433506\n",
      "iteration 100 / 2000: loss 276.854996\n",
      "iteration 200 / 2000: loss 221.719559\n",
      "iteration 300 / 2000: loss 177.733390\n",
      "iteration 400 / 2000: loss 142.790467\n",
      "iteration 500 / 2000: loss 114.578707\n",
      "iteration 600 / 2000: loss 92.257268\n",
      "iteration 700 / 2000: loss 74.298130\n",
      "iteration 800 / 2000: loss 59.924140\n",
      "iteration 900 / 2000: loss 48.350763\n",
      "iteration 1000 / 2000: loss 39.151244\n",
      "iteration 1100 / 2000: loss 31.751116\n",
      "iteration 1200 / 2000: loss 26.012618\n",
      "iteration 1300 / 2000: loss 21.255662\n",
      "iteration 1400 / 2000: loss 17.348513\n",
      "iteration 1500 / 2000: loss 14.352360\n",
      "iteration 1600 / 2000: loss 11.840297\n",
      "iteration 1700 / 2000: loss 9.968243\n",
      "iteration 1800 / 2000: loss 8.326724\n",
      "iteration 1900 / 2000: loss 7.141975\n",
      "iteration 0 / 2000: loss 373.875363\n",
      "iteration 100 / 2000: loss 292.639884\n",
      "iteration 200 / 2000: loss 229.801260\n",
      "iteration 300 / 2000: loss 180.861330\n",
      "iteration 400 / 2000: loss 142.244901\n",
      "iteration 500 / 2000: loss 111.959815\n",
      "iteration 600 / 2000: loss 88.416956\n",
      "iteration 700 / 2000: loss 69.893566\n",
      "iteration 800 / 2000: loss 55.309105\n",
      "iteration 900 / 2000: loss 43.823232\n",
      "iteration 1000 / 2000: loss 34.946344\n",
      "iteration 1100 / 2000: loss 27.819161\n",
      "iteration 1200 / 2000: loss 22.316469\n",
      "iteration 1300 / 2000: loss 17.929489\n",
      "iteration 1400 / 2000: loss 14.503214\n",
      "iteration 1500 / 2000: loss 11.828291\n",
      "iteration 1600 / 2000: loss 9.709770\n",
      "iteration 1700 / 2000: loss 8.185176\n",
      "iteration 1800 / 2000: loss 6.785800\n",
      "iteration 1900 / 2000: loss 5.735724\n",
      "iteration 0 / 2000: loss 401.170225\n",
      "iteration 100 / 2000: loss 308.095641\n",
      "iteration 200 / 2000: loss 237.557584\n",
      "iteration 300 / 2000: loss 182.907222\n",
      "iteration 400 / 2000: loss 141.278824\n",
      "iteration 500 / 2000: loss 109.121833\n",
      "iteration 600 / 2000: loss 84.549390\n",
      "iteration 700 / 2000: loss 65.402640\n",
      "iteration 800 / 2000: loss 50.863863\n",
      "iteration 900 / 2000: loss 39.577265\n",
      "iteration 1000 / 2000: loss 30.973122\n",
      "iteration 1100 / 2000: loss 24.361122\n",
      "iteration 1200 / 2000: loss 19.120982\n",
      "iteration 1300 / 2000: loss 15.185338\n",
      "iteration 1400 / 2000: loss 12.176881\n",
      "iteration 1500 / 2000: loss 9.902643\n",
      "iteration 1600 / 2000: loss 8.068062\n",
      "iteration 1700 / 2000: loss 6.670166\n",
      "iteration 1800 / 2000: loss 5.597010\n",
      "iteration 1900 / 2000: loss 4.740163\n",
      "iteration 0 / 2000: loss 1445.719079\n",
      "iteration 100 / 2000: loss 562.660775\n",
      "iteration 200 / 2000: loss 220.048188\n",
      "iteration 300 / 2000: loss 86.909732\n",
      "iteration 400 / 2000: loss 35.117038\n",
      "iteration 500 / 2000: loss 14.994666\n",
      "iteration 600 / 2000: loss 7.164091\n",
      "iteration 700 / 2000: loss 4.080496\n",
      "iteration 800 / 2000: loss 2.910934\n",
      "iteration 900 / 2000: loss 2.468889\n",
      "iteration 1000 / 2000: loss 2.255949\n",
      "iteration 1100 / 2000: loss 2.189966\n",
      "iteration 1200 / 2000: loss 2.097613\n",
      "iteration 1300 / 2000: loss 2.209431\n",
      "iteration 1400 / 2000: loss 2.148733\n",
      "iteration 1500 / 2000: loss 2.222566\n",
      "iteration 1600 / 2000: loss 2.125045\n",
      "iteration 1700 / 2000: loss 2.237482\n",
      "iteration 1800 / 2000: loss 2.148008\n",
      "iteration 1900 / 2000: loss 2.115386\n",
      "iteration 0 / 2000: loss 1481.301780\n",
      "iteration 100 / 2000: loss 565.268981\n",
      "iteration 200 / 2000: loss 216.805920\n",
      "iteration 300 / 2000: loss 83.915391\n",
      "iteration 400 / 2000: loss 33.222395\n",
      "iteration 500 / 2000: loss 13.982780\n",
      "iteration 600 / 2000: loss 6.696338\n",
      "iteration 700 / 2000: loss 3.912755\n",
      "iteration 800 / 2000: loss 2.880945\n",
      "iteration 900 / 2000: loss 2.438990\n",
      "iteration 1000 / 2000: loss 2.259411\n",
      "iteration 1100 / 2000: loss 2.218961\n",
      "iteration 1200 / 2000: loss 2.174399\n",
      "iteration 1300 / 2000: loss 2.167928\n",
      "iteration 1400 / 2000: loss 2.135671\n",
      "iteration 1500 / 2000: loss 2.230755\n",
      "iteration 1600 / 2000: loss 2.204410\n",
      "iteration 1700 / 2000: loss 2.184388\n",
      "iteration 1800 / 2000: loss 2.186996\n",
      "iteration 1900 / 2000: loss 2.138949\n",
      "iteration 0 / 2000: loss 1519.416245\n",
      "iteration 100 / 2000: loss 568.257495\n",
      "iteration 200 / 2000: loss 213.460734\n",
      "iteration 300 / 2000: loss 81.035373\n",
      "iteration 400 / 2000: loss 31.649032\n",
      "iteration 500 / 2000: loss 13.177615\n",
      "iteration 600 / 2000: loss 6.353687\n",
      "iteration 700 / 2000: loss 3.698355\n",
      "iteration 800 / 2000: loss 2.744723\n",
      "iteration 900 / 2000: loss 2.375837\n",
      "iteration 1000 / 2000: loss 2.232037\n",
      "iteration 1100 / 2000: loss 2.194910\n",
      "iteration 1200 / 2000: loss 2.201471\n",
      "iteration 1300 / 2000: loss 2.142232\n",
      "iteration 1400 / 2000: loss 2.188314\n",
      "iteration 1500 / 2000: loss 2.175427\n",
      "iteration 1600 / 2000: loss 2.168541\n",
      "iteration 1700 / 2000: loss 2.123910\n",
      "iteration 1800 / 2000: loss 2.222282\n",
      "iteration 1900 / 2000: loss 2.168079\n",
      "iteration 0 / 2000: loss 1549.586252\n",
      "iteration 100 / 2000: loss 568.007382\n",
      "iteration 200 / 2000: loss 209.156919\n",
      "iteration 300 / 2000: loss 77.935449\n",
      "iteration 400 / 2000: loss 29.876208\n",
      "iteration 500 / 2000: loss 12.318429\n",
      "iteration 600 / 2000: loss 5.906964\n",
      "iteration 700 / 2000: loss 3.508119\n",
      "iteration 800 / 2000: loss 2.650584\n",
      "iteration 900 / 2000: loss 2.313174\n",
      "iteration 1000 / 2000: loss 2.246690\n",
      "iteration 1100 / 2000: loss 2.166812\n",
      "iteration 1200 / 2000: loss 2.106297\n",
      "iteration 1300 / 2000: loss 2.136534\n",
      "iteration 1400 / 2000: loss 2.216077\n",
      "iteration 1500 / 2000: loss 2.155589\n",
      "iteration 1600 / 2000: loss 2.148312\n",
      "iteration 1700 / 2000: loss 2.240173\n",
      "iteration 1800 / 2000: loss 2.174649\n",
      "iteration 1900 / 2000: loss 2.196239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 2000: loss 1585.233964\n",
      "iteration 100 / 2000: loss 568.825864\n",
      "iteration 200 / 2000: loss 205.479614\n",
      "iteration 300 / 2000: loss 75.102088\n",
      "iteration 400 / 2000: loss 28.298605\n",
      "iteration 500 / 2000: loss 11.576839\n",
      "iteration 600 / 2000: loss 5.553262\n",
      "iteration 700 / 2000: loss 3.351923\n",
      "iteration 800 / 2000: loss 2.611138\n",
      "iteration 900 / 2000: loss 2.324876\n",
      "iteration 1000 / 2000: loss 2.271758\n",
      "iteration 1100 / 2000: loss 2.203569\n",
      "iteration 1200 / 2000: loss 2.217786\n",
      "iteration 1300 / 2000: loss 2.215550\n",
      "iteration 1400 / 2000: loss 2.202872\n",
      "iteration 1500 / 2000: loss 2.139921\n",
      "iteration 1600 / 2000: loss 2.146641\n",
      "iteration 1700 / 2000: loss 2.222759\n",
      "iteration 1800 / 2000: loss 2.192116\n",
      "iteration 1900 / 2000: loss 2.186526\n",
      "iteration 0 / 2000: loss 1620.646407\n",
      "iteration 100 / 2000: loss 570.696060\n",
      "iteration 200 / 2000: loss 202.023803\n",
      "iteration 300 / 2000: loss 72.419363\n",
      "iteration 400 / 2000: loss 26.894677\n",
      "iteration 500 / 2000: loss 10.881265\n",
      "iteration 600 / 2000: loss 5.183559\n",
      "iteration 700 / 2000: loss 3.243820\n",
      "iteration 800 / 2000: loss 2.559514\n",
      "iteration 900 / 2000: loss 2.298175\n",
      "iteration 1000 / 2000: loss 2.194286\n",
      "iteration 1100 / 2000: loss 2.169150\n",
      "iteration 1200 / 2000: loss 2.201971\n",
      "iteration 1300 / 2000: loss 2.161403\n",
      "iteration 1400 / 2000: loss 2.158527\n",
      "iteration 1500 / 2000: loss 2.165497\n",
      "iteration 1600 / 2000: loss 2.204647\n",
      "iteration 1700 / 2000: loss 2.129285\n",
      "iteration 1800 / 2000: loss 2.102988\n",
      "iteration 1900 / 2000: loss 2.200719\n",
      "iteration 0 / 2000: loss 1667.673360\n",
      "iteration 100 / 2000: loss 574.685393\n",
      "iteration 200 / 2000: loss 199.375972\n",
      "iteration 300 / 2000: loss 70.164351\n",
      "iteration 400 / 2000: loss 25.527324\n",
      "iteration 500 / 2000: loss 10.266733\n",
      "iteration 600 / 2000: loss 4.950959\n",
      "iteration 700 / 2000: loss 3.131843\n",
      "iteration 800 / 2000: loss 2.477108\n",
      "iteration 900 / 2000: loss 2.272259\n",
      "iteration 1000 / 2000: loss 2.299116\n",
      "iteration 1100 / 2000: loss 2.209090\n",
      "iteration 1200 / 2000: loss 2.170173\n",
      "iteration 1300 / 2000: loss 2.165066\n",
      "iteration 1400 / 2000: loss 2.158213\n",
      "iteration 1500 / 2000: loss 2.128046\n",
      "iteration 1600 / 2000: loss 2.231786\n",
      "iteration 1700 / 2000: loss 2.130164\n",
      "iteration 1800 / 2000: loss 2.170729\n",
      "iteration 1900 / 2000: loss 2.176970\n",
      "iteration 0 / 2000: loss 220.021432\n",
      "iteration 100 / 2000: loss 164.393949\n",
      "iteration 200 / 2000: loss 124.278515\n",
      "iteration 300 / 2000: loss 93.916655\n",
      "iteration 400 / 2000: loss 71.329456\n",
      "iteration 500 / 2000: loss 54.117832\n",
      "iteration 600 / 2000: loss 41.295346\n",
      "iteration 700 / 2000: loss 31.564122\n",
      "iteration 800 / 2000: loss 24.397008\n",
      "iteration 900 / 2000: loss 18.837560\n",
      "iteration 1000 / 2000: loss 14.581395\n",
      "iteration 1100 / 2000: loss 11.467228\n",
      "iteration 1200 / 2000: loss 9.154494\n",
      "iteration 1300 / 2000: loss 7.420646\n",
      "iteration 1400 / 2000: loss 6.092876\n",
      "iteration 1500 / 2000: loss 4.971743\n",
      "iteration 1600 / 2000: loss 4.385378\n",
      "iteration 1700 / 2000: loss 3.772763\n",
      "iteration 1800 / 2000: loss 3.344830\n",
      "iteration 1900 / 2000: loss 3.011181\n",
      "iteration 0 / 2000: loss 251.026579\n",
      "iteration 100 / 2000: loss 180.851171\n",
      "iteration 200 / 2000: loss 130.784249\n",
      "iteration 300 / 2000: loss 95.326310\n",
      "iteration 400 / 2000: loss 69.305771\n",
      "iteration 500 / 2000: loss 50.842608\n",
      "iteration 600 / 2000: loss 37.288076\n",
      "iteration 700 / 2000: loss 27.547168\n",
      "iteration 800 / 2000: loss 20.552471\n",
      "iteration 900 / 2000: loss 15.519557\n",
      "iteration 1000 / 2000: loss 11.650446\n",
      "iteration 1100 / 2000: loss 9.152051\n",
      "iteration 1200 / 2000: loss 7.103806\n",
      "iteration 1300 / 2000: loss 5.693338\n",
      "iteration 1400 / 2000: loss 4.589823\n",
      "iteration 1500 / 2000: loss 3.860964\n",
      "iteration 1600 / 2000: loss 3.455535\n",
      "iteration 1700 / 2000: loss 3.033308\n",
      "iteration 1800 / 2000: loss 2.695122\n",
      "iteration 1900 / 2000: loss 2.568240\n",
      "iteration 0 / 2000: loss 286.256263\n",
      "iteration 100 / 2000: loss 198.366277\n",
      "iteration 200 / 2000: loss 138.267539\n",
      "iteration 300 / 2000: loss 96.652294\n",
      "iteration 400 / 2000: loss 67.790183\n",
      "iteration 500 / 2000: loss 47.777439\n",
      "iteration 600 / 2000: loss 33.665607\n",
      "iteration 700 / 2000: loss 24.234443\n",
      "iteration 800 / 2000: loss 17.493164\n",
      "iteration 900 / 2000: loss 12.703214\n",
      "iteration 1000 / 2000: loss 9.441530\n",
      "iteration 1100 / 2000: loss 7.250070\n",
      "iteration 1200 / 2000: loss 5.583639\n",
      "iteration 1300 / 2000: loss 4.559685\n",
      "iteration 1400 / 2000: loss 3.884048\n",
      "iteration 1500 / 2000: loss 3.277317\n",
      "iteration 1600 / 2000: loss 2.796375\n",
      "iteration 1700 / 2000: loss 2.639138\n",
      "iteration 1800 / 2000: loss 2.464378\n",
      "iteration 1900 / 2000: loss 2.286038\n",
      "iteration 0 / 2000: loss 314.757291\n",
      "iteration 100 / 2000: loss 209.287195\n",
      "iteration 200 / 2000: loss 140.363207\n",
      "iteration 300 / 2000: loss 94.221952\n",
      "iteration 400 / 2000: loss 63.615623\n",
      "iteration 500 / 2000: loss 43.207561\n",
      "iteration 600 / 2000: loss 29.565455\n",
      "iteration 700 / 2000: loss 20.453736\n",
      "iteration 800 / 2000: loss 14.416119\n",
      "iteration 900 / 2000: loss 10.246302\n",
      "iteration 1000 / 2000: loss 7.427444\n",
      "iteration 1100 / 2000: loss 5.775647\n",
      "iteration 1200 / 2000: loss 4.432116\n",
      "iteration 1300 / 2000: loss 3.637471\n",
      "iteration 1400 / 2000: loss 3.064173\n",
      "iteration 1500 / 2000: loss 2.692249\n",
      "iteration 1600 / 2000: loss 2.464091\n",
      "iteration 1700 / 2000: loss 2.452703\n",
      "iteration 1800 / 2000: loss 2.273992\n",
      "iteration 1900 / 2000: loss 2.174772\n",
      "iteration 0 / 2000: loss 344.482919\n",
      "iteration 100 / 2000: loss 220.807096\n",
      "iteration 200 / 2000: loss 142.141267\n",
      "iteration 300 / 2000: loss 91.836409\n",
      "iteration 400 / 2000: loss 59.570272\n",
      "iteration 500 / 2000: loss 39.127644\n",
      "iteration 600 / 2000: loss 25.760286\n",
      "iteration 700 / 2000: loss 17.311089\n",
      "iteration 800 / 2000: loss 11.838443\n",
      "iteration 900 / 2000: loss 8.251902\n",
      "iteration 1000 / 2000: loss 6.106949\n",
      "iteration 1100 / 2000: loss 4.614683\n",
      "iteration 1200 / 2000: loss 3.701570\n",
      "iteration 1300 / 2000: loss 3.066910\n",
      "iteration 1400 / 2000: loss 2.716622\n",
      "iteration 1500 / 2000: loss 2.428525\n",
      "iteration 1600 / 2000: loss 2.338630\n",
      "iteration 1700 / 2000: loss 2.234492\n",
      "iteration 1800 / 2000: loss 2.076074\n",
      "iteration 1900 / 2000: loss 2.105621\n",
      "iteration 0 / 2000: loss 377.965243\n",
      "iteration 100 / 2000: loss 232.620190\n",
      "iteration 200 / 2000: loss 143.931912\n",
      "iteration 300 / 2000: loss 89.422692\n",
      "iteration 400 / 2000: loss 55.879936\n",
      "iteration 500 / 2000: loss 35.059790\n",
      "iteration 600 / 2000: loss 22.564429\n",
      "iteration 700 / 2000: loss 14.631255\n",
      "iteration 800 / 2000: loss 9.802748\n",
      "iteration 900 / 2000: loss 6.834338\n",
      "iteration 1000 / 2000: loss 5.037538\n",
      "iteration 1100 / 2000: loss 3.906778\n",
      "iteration 1200 / 2000: loss 3.199428\n",
      "iteration 1300 / 2000: loss 2.674661\n",
      "iteration 1400 / 2000: loss 2.427822\n",
      "iteration 1500 / 2000: loss 2.372415\n",
      "iteration 1600 / 2000: loss 2.193781\n",
      "iteration 1700 / 2000: loss 2.182902\n",
      "iteration 1800 / 2000: loss 2.113676\n",
      "iteration 1900 / 2000: loss 2.176594\n",
      "iteration 0 / 2000: loss 409.913054\n",
      "iteration 100 / 2000: loss 242.478161\n",
      "iteration 200 / 2000: loss 144.152495\n",
      "iteration 300 / 2000: loss 86.069026\n",
      "iteration 400 / 2000: loss 51.836401\n",
      "iteration 500 / 2000: loss 31.439209\n",
      "iteration 600 / 2000: loss 19.519413\n",
      "iteration 700 / 2000: loss 12.422466\n",
      "iteration 800 / 2000: loss 8.073298\n",
      "iteration 900 / 2000: loss 5.646579\n",
      "iteration 1000 / 2000: loss 4.256018\n",
      "iteration 1100 / 2000: loss 3.306061\n",
      "iteration 1200 / 2000: loss 2.796712\n",
      "iteration 1300 / 2000: loss 2.546421\n",
      "iteration 1400 / 2000: loss 2.284108\n",
      "iteration 1500 / 2000: loss 2.304526\n",
      "iteration 1600 / 2000: loss 2.186604\n",
      "iteration 1700 / 2000: loss 2.059774\n",
      "iteration 1800 / 2000: loss 2.063432\n",
      "iteration 1900 / 2000: loss 2.113624\n",
      "iteration 0 / 2000: loss 1430.765444\n",
      "iteration 100 / 2000: loss 216.886242\n",
      "iteration 200 / 2000: loss 34.453336\n",
      "iteration 300 / 2000: loss 7.024495\n",
      "iteration 400 / 2000: loss 2.900345\n",
      "iteration 500 / 2000: loss 2.251988\n",
      "iteration 600 / 2000: loss 2.207521\n",
      "iteration 700 / 2000: loss 2.163766\n",
      "iteration 800 / 2000: loss 2.140639\n",
      "iteration 900 / 2000: loss 2.211954\n",
      "iteration 1000 / 2000: loss 2.181940\n",
      "iteration 1100 / 2000: loss 2.172285\n",
      "iteration 1200 / 2000: loss 2.217159\n",
      "iteration 1300 / 2000: loss 2.222103\n",
      "iteration 1400 / 2000: loss 2.168289\n",
      "iteration 1500 / 2000: loss 2.130654\n",
      "iteration 1600 / 2000: loss 2.155181\n",
      "iteration 1700 / 2000: loss 2.139177\n",
      "iteration 1800 / 2000: loss 2.088859\n",
      "iteration 1900 / 2000: loss 2.169953\n",
      "iteration 0 / 2000: loss 1478.372053\n",
      "iteration 100 / 2000: loss 215.147772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 200 / 2000: loss 32.986545\n",
      "iteration 300 / 2000: loss 6.650958\n",
      "iteration 400 / 2000: loss 2.735520\n",
      "iteration 500 / 2000: loss 2.229189\n",
      "iteration 600 / 2000: loss 2.167832\n",
      "iteration 700 / 2000: loss 2.245018\n",
      "iteration 800 / 2000: loss 2.202636\n",
      "iteration 900 / 2000: loss 2.172936\n",
      "iteration 1000 / 2000: loss 2.168218\n",
      "iteration 1100 / 2000: loss 2.203133\n",
      "iteration 1200 / 2000: loss 2.188295\n",
      "iteration 1300 / 2000: loss 2.146845\n",
      "iteration 1400 / 2000: loss 2.126178\n",
      "iteration 1500 / 2000: loss 2.134275\n",
      "iteration 1600 / 2000: loss 2.148131\n",
      "iteration 1700 / 2000: loss 2.196751\n",
      "iteration 1800 / 2000: loss 2.160344\n",
      "iteration 1900 / 2000: loss 2.197771\n",
      "iteration 0 / 2000: loss 1502.717799\n",
      "iteration 100 / 2000: loss 210.157464\n",
      "iteration 200 / 2000: loss 31.012698\n",
      "iteration 300 / 2000: loss 6.199250\n",
      "iteration 400 / 2000: loss 2.712277\n",
      "iteration 500 / 2000: loss 2.225577\n",
      "iteration 600 / 2000: loss 2.188515\n",
      "iteration 700 / 2000: loss 2.218117\n",
      "iteration 800 / 2000: loss 2.139851\n",
      "iteration 900 / 2000: loss 2.184335\n",
      "iteration 1000 / 2000: loss 2.206584\n",
      "iteration 1100 / 2000: loss 2.178684\n",
      "iteration 1200 / 2000: loss 2.205529\n",
      "iteration 1300 / 2000: loss 2.192668\n",
      "iteration 1400 / 2000: loss 2.158723\n",
      "iteration 1500 / 2000: loss 2.116406\n",
      "iteration 1600 / 2000: loss 2.188109\n",
      "iteration 1700 / 2000: loss 2.153464\n",
      "iteration 1800 / 2000: loss 2.172697\n",
      "iteration 1900 / 2000: loss 2.197199\n",
      "iteration 0 / 2000: loss 1550.873093\n",
      "iteration 100 / 2000: loss 208.517875\n",
      "iteration 200 / 2000: loss 29.710858\n",
      "iteration 300 / 2000: loss 5.827213\n",
      "iteration 400 / 2000: loss 2.629791\n",
      "iteration 500 / 2000: loss 2.214067\n",
      "iteration 600 / 2000: loss 2.167351\n",
      "iteration 700 / 2000: loss 2.120786\n",
      "iteration 800 / 2000: loss 2.190357\n",
      "iteration 900 / 2000: loss 2.187227\n",
      "iteration 1000 / 2000: loss 2.132455\n",
      "iteration 1100 / 2000: loss 2.179044\n",
      "iteration 1200 / 2000: loss 2.198519\n",
      "iteration 1300 / 2000: loss 2.173792\n",
      "iteration 1400 / 2000: loss 2.192180\n",
      "iteration 1500 / 2000: loss 2.214257\n",
      "iteration 1600 / 2000: loss 2.178807\n",
      "iteration 1700 / 2000: loss 2.187906\n",
      "iteration 1800 / 2000: loss 2.180152\n",
      "iteration 1900 / 2000: loss 2.189231\n",
      "iteration 0 / 2000: loss 1560.534551\n",
      "iteration 100 / 2000: loss 201.602528\n",
      "iteration 200 / 2000: loss 27.709828\n",
      "iteration 300 / 2000: loss 5.469628\n",
      "iteration 400 / 2000: loss 2.608889\n",
      "iteration 500 / 2000: loss 2.193848\n",
      "iteration 600 / 2000: loss 2.218279\n",
      "iteration 700 / 2000: loss 2.176014\n",
      "iteration 800 / 2000: loss 2.170909\n",
      "iteration 900 / 2000: loss 2.119495\n",
      "iteration 1000 / 2000: loss 2.214323\n",
      "iteration 1100 / 2000: loss 2.179229\n",
      "iteration 1200 / 2000: loss 2.139796\n",
      "iteration 1300 / 2000: loss 2.188842\n",
      "iteration 1400 / 2000: loss 2.170567\n",
      "iteration 1500 / 2000: loss 2.146228\n",
      "iteration 1600 / 2000: loss 2.215217\n",
      "iteration 1700 / 2000: loss 2.185047\n",
      "iteration 1800 / 2000: loss 2.219610\n",
      "iteration 1900 / 2000: loss 2.214795\n",
      "iteration 0 / 2000: loss 1585.832049\n",
      "iteration 100 / 2000: loss 196.724786\n",
      "iteration 200 / 2000: loss 26.162537\n",
      "iteration 300 / 2000: loss 5.067442\n",
      "iteration 400 / 2000: loss 2.552275\n",
      "iteration 500 / 2000: loss 2.244141\n",
      "iteration 600 / 2000: loss 2.210939\n",
      "iteration 700 / 2000: loss 2.103173\n",
      "iteration 800 / 2000: loss 2.126697\n",
      "iteration 900 / 2000: loss 2.163995\n",
      "iteration 1000 / 2000: loss 2.174765\n",
      "iteration 1100 / 2000: loss 2.131928\n",
      "iteration 1200 / 2000: loss 2.146885\n",
      "iteration 1300 / 2000: loss 2.089435\n",
      "iteration 1400 / 2000: loss 2.136665\n",
      "iteration 1500 / 2000: loss 2.219234\n",
      "iteration 1600 / 2000: loss 2.181234\n",
      "iteration 1700 / 2000: loss 2.188428\n",
      "iteration 1800 / 2000: loss 2.217375\n",
      "iteration 1900 / 2000: loss 2.203769\n",
      "iteration 0 / 2000: loss 1628.982336\n",
      "iteration 100 / 2000: loss 194.161169\n",
      "iteration 200 / 2000: loss 24.907337\n",
      "iteration 300 / 2000: loss 4.876492\n",
      "iteration 400 / 2000: loss 2.484340\n",
      "iteration 500 / 2000: loss 2.198501\n",
      "iteration 600 / 2000: loss 2.187551\n",
      "iteration 700 / 2000: loss 2.193695\n",
      "iteration 800 / 2000: loss 2.185121\n",
      "iteration 900 / 2000: loss 2.203015\n",
      "iteration 1000 / 2000: loss 2.189527\n",
      "iteration 1100 / 2000: loss 2.166226\n",
      "iteration 1200 / 2000: loss 2.180982\n",
      "iteration 1300 / 2000: loss 2.209389\n",
      "iteration 1400 / 2000: loss 2.166544\n",
      "iteration 1500 / 2000: loss 2.163223\n",
      "iteration 1600 / 2000: loss 2.201120\n",
      "iteration 1700 / 2000: loss 2.184194\n",
      "iteration 1800 / 2000: loss 2.153609\n",
      "iteration 1900 / 2000: loss 2.113839\n",
      "iteration 0 / 2000: loss 220.019474\n",
      "iteration 100 / 2000: loss 107.575975\n",
      "iteration 200 / 2000: loss 53.904762\n",
      "iteration 300 / 2000: loss 27.588351\n",
      "iteration 400 / 2000: loss 14.519012\n",
      "iteration 500 / 2000: loss 8.183264\n",
      "iteration 600 / 2000: loss 5.119059\n",
      "iteration 700 / 2000: loss 3.461360\n",
      "iteration 800 / 2000: loss 2.836315\n",
      "iteration 900 / 2000: loss 2.282571\n",
      "iteration 1000 / 2000: loss 2.120610\n",
      "iteration 1100 / 2000: loss 2.151913\n",
      "iteration 1200 / 2000: loss 2.015032\n",
      "iteration 1300 / 2000: loss 2.002222\n",
      "iteration 1400 / 2000: loss 1.988009\n",
      "iteration 1500 / 2000: loss 2.021963\n",
      "iteration 1600 / 2000: loss 2.027765\n",
      "iteration 1700 / 2000: loss 1.959876\n",
      "iteration 1800 / 2000: loss 1.997759\n",
      "iteration 1900 / 2000: loss 1.983084\n",
      "iteration 0 / 2000: loss 249.723905\n",
      "iteration 100 / 2000: loss 111.502240\n",
      "iteration 200 / 2000: loss 50.627032\n",
      "iteration 300 / 2000: loss 23.667106\n",
      "iteration 400 / 2000: loss 11.695242\n",
      "iteration 500 / 2000: loss 6.333440\n",
      "iteration 600 / 2000: loss 3.907994\n",
      "iteration 700 / 2000: loss 2.816803\n",
      "iteration 800 / 2000: loss 2.411760\n",
      "iteration 900 / 2000: loss 2.179367\n",
      "iteration 1000 / 2000: loss 2.051567\n",
      "iteration 1100 / 2000: loss 2.216110\n",
      "iteration 1200 / 2000: loss 2.028196\n",
      "iteration 1300 / 2000: loss 2.007640\n",
      "iteration 1400 / 2000: loss 1.982061\n",
      "iteration 1500 / 2000: loss 2.028992\n",
      "iteration 1600 / 2000: loss 1.909592\n",
      "iteration 1700 / 2000: loss 2.023276\n",
      "iteration 1800 / 2000: loss 2.071787\n",
      "iteration 1900 / 2000: loss 1.945647\n",
      "iteration 0 / 2000: loss 283.306944\n",
      "iteration 100 / 2000: loss 113.838335\n",
      "iteration 200 / 2000: loss 47.031181\n",
      "iteration 300 / 2000: loss 20.183231\n",
      "iteration 400 / 2000: loss 9.326580\n",
      "iteration 500 / 2000: loss 5.015584\n",
      "iteration 600 / 2000: loss 3.174191\n",
      "iteration 700 / 2000: loss 2.573799\n",
      "iteration 800 / 2000: loss 2.320380\n",
      "iteration 900 / 2000: loss 2.069206\n",
      "iteration 1000 / 2000: loss 2.072506\n",
      "iteration 1100 / 2000: loss 2.128985\n",
      "iteration 1200 / 2000: loss 1.982956\n",
      "iteration 1300 / 2000: loss 2.046744\n",
      "iteration 1400 / 2000: loss 2.027293\n",
      "iteration 1500 / 2000: loss 2.007047\n",
      "iteration 1600 / 2000: loss 2.084070\n",
      "iteration 1700 / 2000: loss 1.942701\n",
      "iteration 1800 / 2000: loss 2.047420\n",
      "iteration 1900 / 2000: loss 2.040645\n",
      "iteration 0 / 2000: loss 307.858460\n",
      "iteration 100 / 2000: loss 112.364932\n",
      "iteration 200 / 2000: loss 42.235824\n",
      "iteration 300 / 2000: loss 16.633932\n",
      "iteration 400 / 2000: loss 7.363226\n",
      "iteration 500 / 2000: loss 3.982275\n",
      "iteration 600 / 2000: loss 2.789233\n",
      "iteration 700 / 2000: loss 2.274501\n",
      "iteration 800 / 2000: loss 2.114201\n",
      "iteration 900 / 2000: loss 2.119123\n",
      "iteration 1000 / 2000: loss 2.002846\n",
      "iteration 1100 / 2000: loss 2.025508\n",
      "iteration 1200 / 2000: loss 1.978563\n",
      "iteration 1300 / 2000: loss 2.040109\n",
      "iteration 1400 / 2000: loss 2.016612\n",
      "iteration 1500 / 2000: loss 1.983305\n",
      "iteration 1600 / 2000: loss 2.045052\n",
      "iteration 1700 / 2000: loss 2.053721\n",
      "iteration 1800 / 2000: loss 2.116605\n",
      "iteration 1900 / 2000: loss 2.002440\n",
      "iteration 0 / 2000: loss 344.739727\n",
      "iteration 100 / 2000: loss 113.407559\n",
      "iteration 200 / 2000: loss 38.607879\n",
      "iteration 300 / 2000: loss 14.041070\n",
      "iteration 400 / 2000: loss 5.933744\n",
      "iteration 500 / 2000: loss 3.386277\n",
      "iteration 600 / 2000: loss 2.438619\n",
      "iteration 700 / 2000: loss 2.266953\n",
      "iteration 800 / 2000: loss 2.218707\n",
      "iteration 900 / 2000: loss 2.044201\n",
      "iteration 1000 / 2000: loss 2.125876\n",
      "iteration 1100 / 2000: loss 2.074110\n",
      "iteration 1200 / 2000: loss 1.999592\n",
      "iteration 1300 / 2000: loss 2.049558\n",
      "iteration 1400 / 2000: loss 2.070590\n",
      "iteration 1500 / 2000: loss 2.023052\n",
      "iteration 1600 / 2000: loss 2.041981\n",
      "iteration 1700 / 2000: loss 2.122112\n",
      "iteration 1800 / 2000: loss 2.032242\n",
      "iteration 1900 / 2000: loss 2.051551\n",
      "iteration 0 / 2000: loss 377.546953\n",
      "iteration 100 / 2000: loss 112.577042\n",
      "iteration 200 / 2000: loss 35.011260\n",
      "iteration 300 / 2000: loss 11.935456\n",
      "iteration 400 / 2000: loss 5.029853\n",
      "iteration 500 / 2000: loss 2.856466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 600 / 2000: loss 2.303974\n",
      "iteration 700 / 2000: loss 2.151614\n",
      "iteration 800 / 2000: loss 2.019536\n",
      "iteration 900 / 2000: loss 2.016366\n",
      "iteration 1000 / 2000: loss 2.100566\n",
      "iteration 1100 / 2000: loss 2.060689\n",
      "iteration 1200 / 2000: loss 2.078402\n",
      "iteration 1300 / 2000: loss 2.051447\n",
      "iteration 1400 / 2000: loss 2.022960\n",
      "iteration 1500 / 2000: loss 2.026798\n",
      "iteration 1600 / 2000: loss 2.088028\n",
      "iteration 1700 / 2000: loss 2.043891\n",
      "iteration 1800 / 2000: loss 2.085139\n",
      "iteration 1900 / 2000: loss 2.063008\n",
      "iteration 0 / 2000: loss 397.213730\n",
      "iteration 100 / 2000: loss 107.825931\n",
      "iteration 200 / 2000: loss 30.419817\n",
      "iteration 300 / 2000: loss 9.742950\n",
      "iteration 400 / 2000: loss 4.041024\n",
      "iteration 500 / 2000: loss 2.664767\n",
      "iteration 600 / 2000: loss 2.256698\n",
      "iteration 700 / 2000: loss 2.107412\n",
      "iteration 800 / 2000: loss 2.116427\n",
      "iteration 900 / 2000: loss 1.989867\n",
      "iteration 1000 / 2000: loss 2.040491\n",
      "iteration 1100 / 2000: loss 2.013450\n",
      "iteration 1200 / 2000: loss 2.041163\n",
      "iteration 1300 / 2000: loss 2.040140\n",
      "iteration 1400 / 2000: loss 2.079324\n",
      "iteration 1500 / 2000: loss 2.024174\n",
      "iteration 1600 / 2000: loss 2.075777\n",
      "iteration 1700 / 2000: loss 2.001864\n",
      "iteration 1800 / 2000: loss 2.085534\n",
      "iteration 1900 / 2000: loss 2.044675\n",
      "iteration 0 / 2000: loss 1445.770109\n",
      "iteration 100 / 2000: loss 14.360491\n",
      "iteration 200 / 2000: loss 2.275801\n",
      "iteration 300 / 2000: loss 2.180168\n",
      "iteration 400 / 2000: loss 2.176398\n",
      "iteration 500 / 2000: loss 2.199887\n",
      "iteration 600 / 2000: loss 2.176704\n",
      "iteration 700 / 2000: loss 2.149758\n",
      "iteration 800 / 2000: loss 2.197808\n",
      "iteration 900 / 2000: loss 2.171286\n",
      "iteration 1000 / 2000: loss 2.174888\n",
      "iteration 1100 / 2000: loss 2.256435\n",
      "iteration 1200 / 2000: loss 2.214596\n",
      "iteration 1300 / 2000: loss 2.223136\n",
      "iteration 1400 / 2000: loss 2.194701\n",
      "iteration 1500 / 2000: loss 2.259553\n",
      "iteration 1600 / 2000: loss 2.157536\n",
      "iteration 1700 / 2000: loss 2.145759\n",
      "iteration 1800 / 2000: loss 2.074871\n",
      "iteration 1900 / 2000: loss 2.129057\n",
      "iteration 0 / 2000: loss 1497.452129\n",
      "iteration 100 / 2000: loss 13.631789\n",
      "iteration 200 / 2000: loss 2.252828\n",
      "iteration 300 / 2000: loss 2.153128\n",
      "iteration 400 / 2000: loss 2.154495\n",
      "iteration 500 / 2000: loss 2.230549\n",
      "iteration 600 / 2000: loss 2.237370\n",
      "iteration 700 / 2000: loss 2.197519\n",
      "iteration 800 / 2000: loss 2.170865\n",
      "iteration 900 / 2000: loss 2.185462\n",
      "iteration 1000 / 2000: loss 2.179270\n",
      "iteration 1100 / 2000: loss 2.223590\n",
      "iteration 1200 / 2000: loss 2.130861\n",
      "iteration 1300 / 2000: loss 2.130573\n",
      "iteration 1400 / 2000: loss 2.180340\n",
      "iteration 1500 / 2000: loss 2.159731\n",
      "iteration 1600 / 2000: loss 2.200240\n",
      "iteration 1700 / 2000: loss 2.203766\n",
      "iteration 1800 / 2000: loss 2.234692\n",
      "iteration 1900 / 2000: loss 2.170219\n",
      "iteration 0 / 2000: loss 1505.613136\n",
      "iteration 100 / 2000: loss 12.538150\n",
      "iteration 200 / 2000: loss 2.242382\n",
      "iteration 300 / 2000: loss 2.133360\n",
      "iteration 400 / 2000: loss 2.161253\n",
      "iteration 500 / 2000: loss 2.135808\n",
      "iteration 600 / 2000: loss 2.256080\n",
      "iteration 700 / 2000: loss 2.170780\n",
      "iteration 800 / 2000: loss 2.183927\n",
      "iteration 900 / 2000: loss 2.226057\n",
      "iteration 1000 / 2000: loss 2.196343\n",
      "iteration 1100 / 2000: loss 2.178917\n",
      "iteration 1200 / 2000: loss 2.240353\n",
      "iteration 1300 / 2000: loss 2.109711\n",
      "iteration 1400 / 2000: loss 2.141324\n",
      "iteration 1500 / 2000: loss 2.162212\n",
      "iteration 1600 / 2000: loss 2.241151\n",
      "iteration 1700 / 2000: loss 2.226116\n",
      "iteration 1800 / 2000: loss 2.143667\n",
      "iteration 1900 / 2000: loss 2.163925\n",
      "iteration 0 / 2000: loss 1539.182938\n",
      "iteration 100 / 2000: loss 11.752528\n",
      "iteration 200 / 2000: loss 2.243215\n",
      "iteration 300 / 2000: loss 2.213832\n",
      "iteration 400 / 2000: loss 2.206854\n",
      "iteration 500 / 2000: loss 2.160051\n",
      "iteration 600 / 2000: loss 2.154590\n",
      "iteration 700 / 2000: loss 2.189737\n",
      "iteration 800 / 2000: loss 2.202362\n",
      "iteration 900 / 2000: loss 2.233149\n",
      "iteration 1000 / 2000: loss 2.172323\n",
      "iteration 1100 / 2000: loss 2.181125\n",
      "iteration 1200 / 2000: loss 2.195567\n",
      "iteration 1300 / 2000: loss 2.148259\n",
      "iteration 1400 / 2000: loss 2.262236\n",
      "iteration 1500 / 2000: loss 2.187571\n",
      "iteration 1600 / 2000: loss 2.157373\n",
      "iteration 1700 / 2000: loss 2.217401\n",
      "iteration 1800 / 2000: loss 2.183873\n",
      "iteration 1900 / 2000: loss 2.224008\n",
      "iteration 0 / 2000: loss 1575.261901\n",
      "iteration 100 / 2000: loss 11.047405\n",
      "iteration 200 / 2000: loss 2.254286\n",
      "iteration 300 / 2000: loss 2.159757\n",
      "iteration 400 / 2000: loss 2.180236\n",
      "iteration 500 / 2000: loss 2.218832\n",
      "iteration 600 / 2000: loss 2.185200\n",
      "iteration 700 / 2000: loss 2.209948\n",
      "iteration 800 / 2000: loss 2.201625\n",
      "iteration 900 / 2000: loss 2.193940\n",
      "iteration 1000 / 2000: loss 2.245408\n",
      "iteration 1100 / 2000: loss 2.177405\n",
      "iteration 1200 / 2000: loss 2.168068\n",
      "iteration 1300 / 2000: loss 2.170587\n",
      "iteration 1400 / 2000: loss 2.221793\n",
      "iteration 1500 / 2000: loss 2.084474\n",
      "iteration 1600 / 2000: loss 2.224962\n",
      "iteration 1700 / 2000: loss 2.151388\n",
      "iteration 1800 / 2000: loss 2.127543\n",
      "iteration 1900 / 2000: loss 2.188845\n",
      "iteration 0 / 2000: loss 1613.531384\n",
      "iteration 100 / 2000: loss 10.413014\n",
      "iteration 200 / 2000: loss 2.127094\n",
      "iteration 300 / 2000: loss 2.202385\n",
      "iteration 400 / 2000: loss 2.158448\n",
      "iteration 500 / 2000: loss 2.185649\n",
      "iteration 600 / 2000: loss 2.193434\n",
      "iteration 700 / 2000: loss 2.157765\n",
      "iteration 800 / 2000: loss 2.180549\n",
      "iteration 900 / 2000: loss 2.165235\n",
      "iteration 1000 / 2000: loss 2.173115\n",
      "iteration 1100 / 2000: loss 2.185719\n",
      "iteration 1200 / 2000: loss 2.205840\n",
      "iteration 1300 / 2000: loss 2.215103\n",
      "iteration 1400 / 2000: loss 2.224623\n",
      "iteration 1500 / 2000: loss 2.162674\n",
      "iteration 1600 / 2000: loss 2.230634\n",
      "iteration 1700 / 2000: loss 2.175670\n",
      "iteration 1800 / 2000: loss 2.228352\n",
      "iteration 1900 / 2000: loss 2.193015\n",
      "iteration 0 / 2000: loss 1645.021809\n",
      "iteration 100 / 2000: loss 9.717433\n",
      "iteration 200 / 2000: loss 2.161182\n",
      "iteration 300 / 2000: loss 2.196106\n",
      "iteration 400 / 2000: loss 2.155072\n",
      "iteration 500 / 2000: loss 2.252009\n",
      "iteration 600 / 2000: loss 2.194880\n",
      "iteration 700 / 2000: loss 2.180552\n",
      "iteration 800 / 2000: loss 2.245432\n",
      "iteration 900 / 2000: loss 2.198755\n",
      "iteration 1000 / 2000: loss 2.170492\n",
      "iteration 1100 / 2000: loss 2.167770\n",
      "iteration 1200 / 2000: loss 2.185611\n",
      "iteration 1300 / 2000: loss 2.211847\n",
      "iteration 1400 / 2000: loss 2.147642\n",
      "iteration 1500 / 2000: loss 2.205428\n",
      "iteration 1600 / 2000: loss 2.130059\n",
      "iteration 1700 / 2000: loss 2.172276\n",
      "iteration 1800 / 2000: loss 2.213033\n",
      "iteration 1900 / 2000: loss 2.245437\n",
      "lr 1.000000e-07 reg 7.000000e+03 train accuracy: 0.342490 val accuracy: 0.357000\n",
      "lr 1.000000e-07 reg 8.000000e+03 train accuracy: 0.347551 val accuracy: 0.344000\n",
      "lr 1.000000e-07 reg 9.000000e+03 train accuracy: 0.355408 val accuracy: 0.363000\n",
      "lr 1.000000e-07 reg 1.000000e+04 train accuracy: 0.357041 val accuracy: 0.355000\n",
      "lr 1.000000e-07 reg 1.100000e+04 train accuracy: 0.361408 val accuracy: 0.369000\n",
      "lr 1.000000e-07 reg 1.200000e+04 train accuracy: 0.357286 val accuracy: 0.372000\n",
      "lr 1.000000e-07 reg 1.300000e+04 train accuracy: 0.361102 val accuracy: 0.385000\n",
      "lr 1.000000e-07 reg 4.700000e+04 train accuracy: 0.327653 val accuracy: 0.340000\n",
      "lr 1.000000e-07 reg 4.800000e+04 train accuracy: 0.326041 val accuracy: 0.348000\n",
      "lr 1.000000e-07 reg 4.900000e+04 train accuracy: 0.331408 val accuracy: 0.341000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.328184 val accuracy: 0.337000\n",
      "lr 1.000000e-07 reg 5.100000e+04 train accuracy: 0.329898 val accuracy: 0.345000\n",
      "lr 1.000000e-07 reg 5.200000e+04 train accuracy: 0.330000 val accuracy: 0.349000\n",
      "lr 1.000000e-07 reg 5.300000e+04 train accuracy: 0.327184 val accuracy: 0.344000\n",
      "lr 2.000000e-07 reg 7.000000e+03 train accuracy: 0.379122 val accuracy: 0.393000\n",
      "lr 2.000000e-07 reg 8.000000e+03 train accuracy: 0.378286 val accuracy: 0.385000\n",
      "lr 2.000000e-07 reg 9.000000e+03 train accuracy: 0.376551 val accuracy: 0.390000\n",
      "lr 2.000000e-07 reg 1.000000e+04 train accuracy: 0.376694 val accuracy: 0.385000\n",
      "lr 2.000000e-07 reg 1.100000e+04 train accuracy: 0.373714 val accuracy: 0.398000\n",
      "lr 2.000000e-07 reg 1.200000e+04 train accuracy: 0.369347 val accuracy: 0.384000\n",
      "lr 2.000000e-07 reg 1.300000e+04 train accuracy: 0.371306 val accuracy: 0.386000\n",
      "lr 2.000000e-07 reg 4.700000e+04 train accuracy: 0.331102 val accuracy: 0.342000\n",
      "lr 2.000000e-07 reg 4.800000e+04 train accuracy: 0.329000 val accuracy: 0.337000\n",
      "lr 2.000000e-07 reg 4.900000e+04 train accuracy: 0.332510 val accuracy: 0.356000\n",
      "lr 2.000000e-07 reg 5.000000e+04 train accuracy: 0.322449 val accuracy: 0.338000\n",
      "lr 2.000000e-07 reg 5.100000e+04 train accuracy: 0.328306 val accuracy: 0.343000\n",
      "lr 2.000000e-07 reg 5.200000e+04 train accuracy: 0.327571 val accuracy: 0.342000\n",
      "lr 2.000000e-07 reg 5.300000e+04 train accuracy: 0.321694 val accuracy: 0.350000\n",
      "lr 5.000000e-07 reg 7.000000e+03 train accuracy: 0.382061 val accuracy: 0.397000\n",
      "lr 5.000000e-07 reg 8.000000e+03 train accuracy: 0.377735 val accuracy: 0.390000\n",
      "lr 5.000000e-07 reg 9.000000e+03 train accuracy: 0.376102 val accuracy: 0.384000\n",
      "lr 5.000000e-07 reg 1.000000e+04 train accuracy: 0.373918 val accuracy: 0.383000\n",
      "lr 5.000000e-07 reg 1.100000e+04 train accuracy: 0.362265 val accuracy: 0.379000\n",
      "lr 5.000000e-07 reg 1.200000e+04 train accuracy: 0.365776 val accuracy: 0.380000\n",
      "lr 5.000000e-07 reg 1.300000e+04 train accuracy: 0.361306 val accuracy: 0.376000\n",
      "lr 5.000000e-07 reg 4.700000e+04 train accuracy: 0.333204 val accuracy: 0.339000\n",
      "lr 5.000000e-07 reg 4.800000e+04 train accuracy: 0.317041 val accuracy: 0.339000\n",
      "lr 5.000000e-07 reg 4.900000e+04 train accuracy: 0.327245 val accuracy: 0.338000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.324857 val accuracy: 0.339000\n",
      "lr 5.000000e-07 reg 5.100000e+04 train accuracy: 0.329816 val accuracy: 0.345000\n",
      "lr 5.000000e-07 reg 5.200000e+04 train accuracy: 0.320592 val accuracy: 0.327000\n",
      "lr 5.000000e-07 reg 5.300000e+04 train accuracy: 0.322714 val accuracy: 0.339000\n",
      "best validation accuracy achieved during cross-validation: 0.398000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "# learning_rates = np.linspace(1e-7, 5e-7, 5)\n",
    "# regularization_strengths = np.linspace(2.5e4, 5e4, 6)\n",
    "\n",
    "learning_rates = [1e-7, 2e-7, 5e-7]\n",
    "#regularization_strengths = [5e4, 1e8]\n",
    "regularization_strengths =[(1+0.1*i)*1e4 for i in range(-3,4)] + [(5+0.1*i)*1e4 for i in range(-3,4)]\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "\n",
    "for rate in learning_rates:\n",
    "    for reg_now in regularization_strengths:\n",
    "        softmax = Softmax()\n",
    "        softmax.train(X_train, y_train, learning_rate=rate, reg=reg_now, num_iters=2000, verbose=True)\n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        training_accuracy = np.mean(y_train == y_train_pred)\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        validation_accuracy = np.mean(y_val == y_val_pred)\n",
    "        results[(rate, reg_now)] = (training_accuracy, validation_accuracy)\n",
    "        if validation_accuracy > best_val:\n",
    "            best_val = validation_accuracy\n",
    "            best_softmax = softmax\n",
    "\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.373000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 2** - *True or False*\n",
    "\n",
    "Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$ *True.*\n",
    "\n",
    "\n",
    "$\\color{blue}{\\textit Your Explanation:}$\n",
    "The softmax classifier is the minimum loss value. For the correct classification, the higher the probability is always obtained. The error classification always gets a lower possibility, so that the loss value is smaller. However, the SVM is different, as long as the loss value reaches zero, it will not improve the accuracy of the correct classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
